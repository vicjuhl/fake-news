{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate distribtion between fake and reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.mappings import labels\n",
    "labels = {\n",
    "    \"fake\": \"fake\",\n",
    "    \"bias\": \"fake\",\n",
    "    \"junksci\": \"fake\",\n",
    "    \"hate\": \"fake\",\n",
    "    \"reliable\": \"reliable\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New dataframe with id, orig_type, type, and duplicates=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_file = pl.Path(os.path.abspath('')).parent.parent.resolve() / \"data_files/corpus/news_cleaned_2018_02_13.csv\"\n",
    "dups_path = pl.Path(os.path.abspath('')).parent.parent.resolve() / \"data_files/corpus/duplicates.csv\"\n",
    "to_path = pl.Path(os.path.abspath('')).parent.parent.resolve() / \"data_files/corpus/\"\n",
    "file_name = \"duplicate_distribution.csv\"\n",
    "\n",
    "def get_dups_distribution(from_file: pl.Path, dups_path: pl.Path, to_path: pl.Path, file_name: pl.Path) -> None:\n",
    "    \"\"\"Get id, type and orig_type for all duplicates in source dataset.\n",
    "\n",
    "    Writes a file to the directory\n",
    "    \"\"\"\n",
    "    # load id and type from source file\n",
    "    df = pd.read_csv(from_file, usecols=['id','type'])\n",
    "    print(f\"Nulls found: \\n{df.isnull().sum()}\")\n",
    "    df = df[df['type'].notnull()]               # filter\n",
    "    df = df.rename(columns={'type':'orig_type'})\n",
    "    df['type'] = df['orig_type'].map(labels)\n",
    "\n",
    "    label_counts = df['orig_type'].value_counts()\n",
    "\n",
    "    # load id from duplicates file\n",
    "    df_dups = pd.read_csv(dups_path)\n",
    "    df_dups['duplicate'] = True                 # add duplicate column\n",
    "    # merge source file with duplicate check\n",
    "    df = df.merge(df_dups,\"left\",on=\"id\")       # match duplicate IDs in source file\n",
    "    df = df[df['duplicate'].notnull()]          # filter results to show only duplicate IDs and orig_type\n",
    "    df.to_csv(to_path / file_name, index=False)\n",
    "    print(f\"\\n Distribution of duplicate IDs over type was written to {to_path}/{file_name}\")\n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/hj39jtf940s2chfk3bnbmsqm0000gn/T/ipykernel_14392/1657095944.py:12: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(from_file, usecols=['id','type'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls found: \n",
      "id      1654589\n",
      "type    2057872\n",
      "dtype: int64\n",
      "\n",
      " Distribution of duplicate IDs over type was written to /Users/victor/Documents/Uddannelse/Repos/fake-news/data_files/corpus/duplicate_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "orig_label_count = get_dups_distribution(from_file, dups_path, to_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bias        322657\n",
       "fake        128710\n",
       "reliable    103089\n",
       "junksci      31784\n",
       "hate          9741\n",
       "Name: orig_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(to_path / file_name)\n",
    "df['orig_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bias', 'fake', 'reliable', 'junksci', 'hate'],\n",
       " [1138998, 894746, 1913222, 117467, 76496],\n",
       " [322657, 128710, 103089, 31784, 9741]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_labs = [\"bias\",\"fake\",\"reliable\",\"junksci\",\"hate\"]\n",
    "\n",
    "pre_label_count = []\n",
    "for lab in orig_labs:\n",
    "    pre_label_count.append(orig_label_count[lab])\n",
    "\n",
    "dups_label_count = []\n",
    "for i in range(len(orig_labs)):\n",
    "    dups_label_count.append(df['orig_type'].value_counts()[i])\n",
    "\n",
    "data_export = []\n",
    "data_export.append(orig_labs)\n",
    "data_export.append(pre_label_count)\n",
    "data_export.append(dups_label_count)\n",
    "data_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
